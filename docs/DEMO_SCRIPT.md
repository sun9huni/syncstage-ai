# SyncStage AI — 피칭 대본 (3분 데모)

> **🎤 발표자 준비사항:**
> - 라이브 URL: `https://syncstage-ai.vercel.app`
> - 화면 최대화 (전체화면 F11 권장)
> - 오디오 출력 볼륨 적정 수준 확인

---

## ⏱️ 0:00 — 인트로 (Problem & Solution, 30초)

"안녕하세요. 대한민국 엔터테인먼트 산업의 고질적인 병폐를 해결할 **SyncStage AI** 팀입니다.

완벽한 K-pop 무대를 만들기 위해 A&R 디렉터, 안무가, 비주얼 팀이 매번 수십 번씩 피드백을 주고받는 과정을 아시나요? 음원 하이라이트 구간에 어떤 안무가 들어가야 할지, 어떤 의상이 어울릴지 소통하는 물리적·금전적 비용은 막대합니다.

저희는 **Gemini의 네이티브 오디오 멀티모달 분석 능력과 Function Calling 기술**을 활용해, 음원을 올리기만 하면 즉각적으로 안무 초안을 짜고 자연어로 수정할 수 있는 **AI A&R 디렉터 에이전트**를 만들었습니다."

---

## ⏱️ 0:30 — 데모 1: 음원 자동 분석 & 안무 초안 (50초)

"*(헤더의 `⚡ Use Built-in K-pop Demo Track` 버튼 클릭)*

자, 기획사에 새로운 데모 음원이 도착했습니다. 버튼 하나로 음원이 로드됩니다.

*(Analyze with Gemini 버튼 클릭)*

지금 Gemini 3 Flash Preview가 이 음원을 직접 듣고 있습니다. 별도의 오디오 분석 라이브러리가 없습니다. Gemini의 네이티브 오디오 이해력만으로 드럼 킥, 베이스 라인, 비트 드롭의 정확한 타임스탬프를 추출합니다.

*(분석 완료 → Phase 3 리포트 등장)*

보시면, AI가 곡의 구조와 에너지 흐름을 리포트 형태로 정리해 줍니다.

*(Generate Choreography 버튼 클릭 → 타임라인 등장)*

5개 세그먼트로 구성된 안무 타임라인이 자동 생성됩니다. 재생 버튼을 눌러보겠습니다.

*(▶ 재생 클릭)*

좌측 3D 아바타를 보시면, 인트로의 가벼운 idle 모션에서 비트 드롭 구간에 arms_hiphop 파워 무브로 전환되는 것이 보입니다."

---

## ⏱️ 1:20 — 데모 2: 자연어 패치 & Function Calling (50초)

"기존 AI 도구의 한계는 '부분 수정'이 어렵다는 것입니다. 저희의 핵심 경쟁력은 **의도 기반 패치**입니다.

*(채팅창에 입력: '마지막 파트 안무를 재즈 댄스로 바꿔줘')*

A&R 디렉터가 피드백을 주면, Gemini는 전체 데이터를 새로 쓰는 것이 아니라 **Function Calling**을 통해 `update_segment` 도구를 정확히 선택해 해당 구간만 타겟하여 수정합니다.

*(타임라인 업데이트 확인)*

보이시나요? Revision 번호가 올라가며 변경 이력이 기록됩니다. 3D 아바타의 모션이 즉각 변경됩니다."

---

## ⏱️ 2:10 — 데모 3: 무대 의상 비주얼 생성 (30초)

"안무가 정해졌으니, 무대 의상을 시각화해 보겠습니다.

*(Generate Wardrobe 버튼 클릭)*

Gemini가 오디오 무드 분석에서 도출한 프롬프트를 **Gemini Flash Image Generation** 모델이 K-pop 매거진 퀄리티의 의상 컨셉 이미지로 렌더링합니다.

*(이미지 등장 → 우측 상단 `✨ Gemini Image` 배지 지목)*

구글의 이미지 생성 모델이 만든 결과물입니다."

---

## ⏱️ 2:40 — 아웃트로 (20초)

"SyncStage AI는 단순한 안무 생성 도구가 아닙니다. A&R 디렉터, 안무가, 스타일리스트가 하나의 대시보드에서 자연어로 소통하게 만드는 **차세대 엔터테인먼트 B2B 협업 툴**입니다.

무작위 비디오 생성이 아닌 JSON 기반의 데이터 오케스트레이션을 택했기에 상용화가 가능한 아키텍처입니다.

**Gemini 네이티브 오디오 분석, Function Calling 에이전트, Gemini 이미지 생성**의 삼위일체가 있었기에 이 속도와 정밀도가 가능했습니다. 감사합니다."
